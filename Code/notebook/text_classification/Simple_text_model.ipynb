{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 7789\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import string, re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def tokenize_with_lemmentize(document ,lemmentize = True):\n",
    "#Tokenizer and Lemmantizer for TfidfVectorizer\n",
    "#First remove url, then remove stopwords and non-alphabet, and lemmantize the lower cased tokens. \n",
    "\n",
    "    tokenized_post = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    removed = stopwords.words('english') + list(string.punctuation)\n",
    "    document =  re.sub(r'http\\S+', '', str(document))\n",
    "    tokens = word_tokenize(document)\n",
    "    \n",
    "    words = [word.lower() for word in tokens if word.isalpha() and word not in removed]\n",
    "    if lemmentize:\n",
    "        words_lemmantized = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words]\n",
    "        tokenized_post += words_lemmantized\n",
    "    else:\n",
    "        tokenized_post += words\n",
    "    return tokenized_post\n",
    "def concat_messages(df):\n",
    "    df.post_name.fillna('', inplace=True)\n",
    "    df.post_message.fillna('', inplace=True)\n",
    "    df.post_description.fillna('', inplace=True)\n",
    "    df['concat'] = df.post_name + ' ' + df.post_message + ' ' + df.post_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home3/r05322021/Desktop/FB_hatecrime/Data/label/immigration_label.csv', encoding='utf-8', engine='python')\n",
    "df = df[(df.Mexican_related.isin([0,1])) & (df.Muslim_related.isin([0,1])) & (df.immigration_related.isin([0,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'concat'\n",
    "# y_col = 'Ethnics_related'\n",
    "concat_messages(df)\n",
    "target = df.dropna(subset=[col]).copy()\n",
    "# target = down_sample(target, y_col)\n",
    "target[col] = target[col].str.replace('\\r', '').str.lower()\n",
    "# target[y_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(tokenizer=tokenize_with_lemmentize, \n",
    "                      token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', \n",
    "                      min_df=5\n",
    "                     )\n",
    "X = bow.fit_transform(target[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer().fit(X)\n",
    "tfidf_X = tfidf.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3.45616666, 1.49064704, 3.74834289, ..., 6.66254133, 3.61531977,\n",
       "         1.30712094]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=7789, shuffle=True)\n",
    "y_col = 'immigration_related'\n",
    "target[y_col] = target[y_col].astype('category')\n",
    "y = target[y_col].cat.codes.values\n",
    "def kfold(X, y):\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        yield (X[train_idx], y[train_idx], X[valid_idx], y[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_map = dict(enumerate(target[y_col].cat.categories))\n",
    "def random_show(indexes, pred, prob):\n",
    "    print(y_map)\n",
    "    #for idx, p in random.sample(list(zip(indexes, pred)), k=min(len(indexes), 5)):\n",
    "    for idx, p, probability in zip(indexes, pred, prob):\n",
    "        row = target.iloc[idx]\n",
    "        print('\\n', '\\n'.join([row.post_name, row.post_message, row.post_description]), \n",
    "              '\\nprediction', y_map[p], 'groundtruth', row[y_col], \n",
    "              'prob', {y_map[i]: probability[i] for i in range(2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train 0.9385823960007141 valid 0.7987152034261242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.84      0.86      1008\n",
      "         Yes       0.63      0.69      0.66       393\n",
      "\n",
      "    accuracy                           0.80      1401\n",
      "   macro avg       0.75      0.77      0.76      1401\n",
      "weighted avg       0.81      0.80      0.80      1401\n",
      "\n",
      "accuracy train 0.9396536332797715 valid 0.7987152034261242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.83      0.85       988\n",
      "         Yes       0.64      0.72      0.68       413\n",
      "\n",
      "    accuracy                           0.80      1401\n",
      "   macro avg       0.76      0.77      0.77      1401\n",
      "weighted avg       0.81      0.80      0.80      1401\n",
      "\n",
      "accuracy train 0.9394858978936095 valid 0.8014285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.83      0.86      1003\n",
      "         Yes       0.63      0.72      0.67       397\n",
      "\n",
      "    accuracy                           0.80      1400\n",
      "   macro avg       0.76      0.78      0.77      1400\n",
      "weighted avg       0.81      0.80      0.81      1400\n",
      "\n",
      "accuracy train 0.9421635130310604 valid 0.7971428571428572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.83      0.85       974\n",
      "         Yes       0.65      0.73      0.69       426\n",
      "\n",
      "    accuracy                           0.80      1400\n",
      "   macro avg       0.76      0.78      0.77      1400\n",
      "weighted avg       0.81      0.80      0.80      1400\n",
      "\n",
      "accuracy train 0.9430560514102106 valid 0.7921428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.84      0.85       965\n",
      "         Yes       0.66      0.70      0.68       435\n",
      "\n",
      "    accuracy                           0.79      1400\n",
      "   macro avg       0.76      0.77      0.76      1400\n",
      "weighted avg       0.80      0.79      0.79      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "for train_idx, valid_idx in kf.split(tfidf_X):\n",
    "    X_train, y_train, X_valid, y_valid = tfidf_X[train_idx], y[train_idx], tfidf_X[valid_idx], y[valid_idx]\n",
    "    logit_m = LogisticRegression(\n",
    "        random_state=7789, multi_class='ovr', solver='liblinear',\n",
    "        class_weight={0:1, 1:2.5}, penalty='l2', C=5).fit(X_train, y_train)\n",
    "    print('accuracy train', logit_m.score(X_train, y_train), 'valid', logit_m.score(X_valid, y_valid))\n",
    "    \n",
    "    pred = logit_m.predict(X_valid)\n",
    "    print(classification_report(y_valid, pred, target_names=['No', 'Yes']))\n",
    "#     errors = valid_idx[pred != y_valid]\n",
    "#     random_show(errors.tolist(), pred[pred != y_valid], logit_m.predict_proba(X_valid)[pred != y_valid])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      " 0.963756472058561 0.7994289793004996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.75      0.81       781\n",
      "         Yes       0.73      0.86      0.79       620\n",
      "\n",
      "    accuracy                           0.80      1401\n",
      "   macro avg       0.80      0.81      0.80      1401\n",
      "weighted avg       0.81      0.80      0.80      1401\n",
      "\n",
      "[LibSVM]\n",
      " 0.9607212997678986 0.7865810135617416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.74      0.80       816\n",
      "         Yes       0.70      0.85      0.77       585\n",
      "\n",
      "    accuracy                           0.79      1401\n",
      "   macro avg       0.79      0.80      0.79      1401\n",
      "weighted avg       0.80      0.79      0.79      1401\n",
      "\n",
      "[LibSVM]\n",
      " 0.9628704034273474 0.795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.77      0.82       832\n",
      "         Yes       0.71      0.84      0.77       568\n",
      "\n",
      "    accuracy                           0.80      1400\n",
      "   macro avg       0.79      0.80      0.79      1400\n",
      "weighted avg       0.81      0.80      0.80      1400\n",
      "\n",
      "[LibSVM]\n",
      " 0.9623348803998572 0.7871428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.75      0.81       843\n",
      "         Yes       0.69      0.84      0.76       557\n",
      "\n",
      "    accuracy                           0.79      1400\n",
      "   macro avg       0.78      0.80      0.78      1400\n",
      "weighted avg       0.80      0.79      0.79      1400\n",
      "\n",
      "[LibSVM]\n",
      " 0.9641199571581578 0.7935714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.76      0.81       809\n",
      "         Yes       0.72      0.84      0.78       591\n",
      "\n",
      "    accuracy                           0.79      1400\n",
      "   macro avg       0.79      0.80      0.79      1400\n",
      "weighted avg       0.80      0.79      0.79      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "for X_train, y_train, X_valid, y_valid in kfold(tfidf_X, y):\n",
    "    svm_m = SVC(random_state=SEED, verbose=True, gamma='scale', class_weight={0:1, 1:2}).fit(X_train, y_train)\n",
    "    print('\\n', svm_m.score(X_train, y_train), svm_m.score(X_valid, y_valid))\n",
    "    pred = svm_m.predict(X_valid)\n",
    "    print(classification_report(y_valid, pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.95      0.87      0.91      4938\n",
      "         Yes       0.74      0.88      0.80      2064\n",
      "\n",
      "    accuracy                           0.87      7002\n",
      "   macro avg       0.84      0.88      0.86      7002\n",
      "weighted avg       0.89      0.87      0.88      7002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_m = LogisticRegression(\n",
    "        random_state=7789, multi_class='ovr', solver='liblinear', class_weight={0:1, 1:2.5}).fit(tfidf_X, y)\n",
    "pred = logit_m.predict(tfidf_X)\n",
    "print(classification_report(y, pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.99      1.00      6356\n",
      "         Yes       0.93      1.00      0.96       646\n",
      "\n",
      "    accuracy                           0.99      7002\n",
      "   macro avg       0.97      1.00      0.98      7002\n",
      "weighted avg       0.99      0.99      0.99      7002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_m = SVC(random_state=SEED, verbose=True, gamma='scale', class_weight={0:1, 1:13}).fit(tfidf_X, y)\n",
    "pred = svm_m.predict(tfidf_X)\n",
    "print(classification_report(y, pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home3/r05322021/Desktop/model/LR/immigration_logit.joblib']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(logit_m, f'/home3/r05322021/Desktop/model/LR/{y_col[:-8]}_logit.joblib')\n",
    "# dump(svm_m, f'/home3/r05322021/Desktop/model/SVM/{y_col[:-8]}_svm.joblib')\n",
    "# dump(bow, '/home3/r05322021/Desktop/model/transformation/BagOfWord_immigration.joblib')\n",
    "# dump(tfidf, '/home3/r05322021/Desktop/model/transformation/TFIDF_immigration.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'immigration'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col[:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FB",
   "language": "python",
   "name": "fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
