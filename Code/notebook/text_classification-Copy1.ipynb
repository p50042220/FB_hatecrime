{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from tensorflow.keras.models import  Model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.1.0\n",
      "Hub version:  0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow Version:\",tf.__version__)\n",
    "print(\"Hub version: \",hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_layer=hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home3/r05322021/Desktop/FB_hatecrime/Data/label/race_label.csv', encoding='utf-8', engine='python')\n",
    "df = df[df.Ethnics_related == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ethnic_negative'] = df['Ethnic_sentiment'].apply(lambda x: 1 if x == -1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15763288819062582"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.Ethnic_negative == 1])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n",
    "# df.loc[df[df.immigration_related == 4].index, 'immigration_related'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(df, target_col):\n",
    "    df = df[df[target_col].notnull()]\n",
    "    df = df.fillna('')\n",
    "    for index in df.index:\n",
    "        for column in ['post_name', 'post_message', 'post_description']:\n",
    "            text = df.loc[index, column]\n",
    "            text = re.sub(r'http\\S+', '', str(text))\n",
    "            text = re.sub(r'\\@\\w+', '', str(text))\n",
    "            text = re.sub(r'#\\w+', '', str(text))\n",
    "            text = re.sub(r'\\[\\w+\\]', '', str(text))\n",
    "            text = re.sub(r'\\n', '', str(text))\n",
    "            text = re.sub(r'\\r', '', str(text))\n",
    "            df.loc[index, column] = text\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        #Cutting down the excess length\n",
    "        tokens = tokens[0:max_seq_length]\n",
    "        return [1]*len(tokens)\n",
    "    else :\n",
    "      return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "    if len(tokens)>max_seq_length:\n",
    "      #Cutting down the excess length\n",
    "      tokens = tokens[:max_seq_length]\n",
    "      segments = []\n",
    "      current_segment_id = 0\n",
    "      for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "          current_segment_id = 1\n",
    "      return segments\n",
    "    else:\n",
    "      segments = []\n",
    "      current_segment_id = 0\n",
    "      for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "          current_segment_id = 1\n",
    "      return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):    \n",
    "    if len(tokens) > max_seq_length:\n",
    "      tokens = tokens[:max_seq_length]\n",
    "      token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "      return token_ids\n",
    "    else:\n",
    "      token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "      input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "      return input_ids\n",
    "\n",
    "def preprocess_text(s, tokenizer, max_length):\n",
    "    stokens = tokenizer.tokenize(s)\n",
    "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "    input_ids = get_ids(stokens, tokenizer, max_length)\n",
    "    input_masks = get_masks(stokens, max_length)\n",
    "    input_segments = get_segments(stokens, max_length)\n",
    "    return input_ids, input_masks, input_segments\n",
    "\n",
    "def preprocess_whole(df, tokenizer, max_length, y_col):\n",
    "    \n",
    "    df = text_clean(df, y_col)\n",
    "    input_id, input_mask, input_segment = [], [], []\n",
    "    \n",
    "    for _, index in enumerate(tqdm(df.index.tolist(), total=len(df)), 1):\n",
    "        text = df['post_name'].loc[index] + ' ' + df['post_message'].loc[index] + ' ' + df['post_description'].loc[index]\n",
    "        ids, masks, segments = preprocess_text(text, tokenizer, max_length)\n",
    "        \n",
    "        input_id.append(ids)\n",
    "        input_mask.append(masks)\n",
    "        input_segment.append(segments)\n",
    "        \n",
    "    return [np.array(input_id, dtype=np.int32), \n",
    "            np.array(input_mask, dtype=np.int32), \n",
    "            np.array(input_segment, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_test_split(df, sample_num=100):\n",
    "    index = df.index.tolist()\n",
    "    test = random.sample(index, sample_num)\n",
    "    index = set(index) - set(test)\n",
    "    val = random.sample(index, sample_num)\n",
    "    train = set(index) - set(val)\n",
    "    \n",
    "    train = df.loc[train]\n",
    "    val = df.loc[val]\n",
    "    test = df.loc[test]\n",
    "    return train, val, test\n",
    "\n",
    "def training_form(df, sample_num, max_length, y_col):\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file,do_lower_case)\n",
    "    train, val, test = train_test_split(df, sample_num)\n",
    "    train_doc = train\n",
    "    \n",
    "    X_train = preprocess_whole(train, tokenizer, max_length, y_col)\n",
    "    X_val = preprocess_whole(val, tokenizer, max_length, y_col)\n",
    "    X_test = preprocess_whole(test, tokenizer, max_length, y_col)\n",
    "        \n",
    "    onehotencoder = OneHotEncoder()\n",
    "    y_train = onehotencoder.fit_transform(np.array(train[y_col]).reshape(-1, 1)).toarray()\n",
    "    y_val = onehotencoder.fit_transform(np.array(val[y_col]).reshape(-1, 1)).toarray()\n",
    "    y_test = onehotencoder.fit_transform(np.array(test[y_col]).reshape(-1, 1)).toarray()\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [00:15<00:00, 239.29it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 757.52it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 573.38it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = training_form(df, 100, MAX_SEQ_LEN, 'Ethnic_negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
    "                                       name=\"input_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "input_segment = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
    "                                    name=\"input_segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output, sequence_output = bert_layer([input_ids, input_mask, input_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv1D(filters=64, activation='relu', kernel_size=5, strides=1)(sequence_output)\n",
    "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"dense_output\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "      inputs=[input_ids, input_mask, input_segment], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15763288819062582"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.Ethnic_sentiment == -1])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3619 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "3619/3619 - 1556s - loss: 0.5800 - accuracy: 0.8450 - val_loss: 1.8940 - val_accuracy: 0.7100\n",
      "Epoch 2/5\n",
      "3619/3619 - 1611s - loss: 0.3536 - accuracy: 0.9301 - val_loss: 2.3451 - val_accuracy: 0.7400\n",
      "Epoch 3/5\n",
      "3619/3619 - 1639s - loss: 0.2350 - accuracy: 0.9693 - val_loss: 3.1542 - val_accuracy: 0.7700\n",
      "Epoch 4/5\n",
      "3619/3619 - 1604s - loss: 0.1777 - accuracy: 0.9754 - val_loss: 2.8220 - val_accuracy: 0.7700\n",
      "Epoch 5/5\n",
      "3619/3619 - 1648s - loss: 0.1437 - accuracy: 0.9831 - val_loss: 2.4181 - val_accuracy: 0.7700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3908614390>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=5,batch_size=128,verbose=2,validation_data=[X_val, Y_val], class_weight={0:1, 1:8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 34s 339ms/sample - loss: 0.6244 - accuracy: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6243823659420014, 0.76]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "def predict(original_df, threshold, model):\n",
    "    \n",
    "    prediction = model.predict(original_df, batch_size=128)\n",
    "    pred = [1 if d[1] >= threshold else 0 for d in prediction]\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# Evaluation\n",
    "def Evaluation(original_df, original_label, model, threshold=0.5):\n",
    "    \n",
    "    Y = [0 if element[0] == 1 else 1 for element in original_label]\n",
    "    prediction = predict(original_df, threshold=threshold, model=model)\n",
    "    accuracy = metrics.accuracy_score(Y, prediction)\n",
    "\n",
    "    target_names = ['ACTIVE', 'CHURN']\n",
    "    report = classification_report(Y, prediction, target_names=target_names)\n",
    "\n",
    "    return [accuracy, report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ACTIVE       0.87      0.85      0.86        85\n",
      "       CHURN       0.24      0.27      0.25        15\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.55      0.56      0.55       100\n",
      "weighted avg       0.77      0.76      0.77       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = Evaluation(X_test, Y_test, model)\n",
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(r'/home3/r05322021/Desktop/FB_hatecrime/model/race_negative.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FB",
   "language": "python",
   "name": "fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
